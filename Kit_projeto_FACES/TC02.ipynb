{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfc3ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import mode \n",
    "from scipy.linalg import det\n",
    "from matplotlib.pylab import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ede8e6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[H\u001b[2JIniciando carregamento e pré-processamento das imagens...\n"
     ]
    }
   ],
   "source": [
    "# Limpa o console \n",
    "os.system('cls' if os.name == 'nt' else 'clear')\n",
    "part1 = 'subject0'\n",
    "part2 = 'subject'\n",
    "part3 = ['.centerlight', '.glasses', '.happy', '.leftlight', '.noglasses', '.normal', '.rightlight', '.sad', '.sleepy', '.surprised', '.wink']\n",
    "\n",
    "Nind = 15   # Quantidade de individuos (classes)\n",
    "Nexp = len(part3)  # Quantidade de expressoes\n",
    "\n",
    "X = []  # Lista para acumular imagens vetorizadas\n",
    "Y = []  # Lista para acumular o rotulo (identificador) do individuo\n",
    "\n",
    "print(\"Iniciando carregamento e pré-processamento das imagens...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "449dcf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagens carregadas e vetorizadas. Dimensão de X: (400, 165)\n",
      "Dimensão de Y: (165,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, Nind + 1):  # Indice para os individuos\n",
    "    individuo = i\n",
    "    # print(f\"Processando indivíduo: {individuo}\") # Descomente para ver o progresso detalhado\n",
    "    for j in range(Nexp):   # Indice para expressoes\n",
    "        if i < 10:\n",
    "            nome = f\"{part1}{i}{part3[j]}\"    # Monta o nome do arquivo de imagem\n",
    "        else:\n",
    "            nome = f\"{part2}{i}{part3[j]}\"\n",
    "\n",
    "        try:\n",
    "            Img = Image.open(nome).convert('L')  # le imagem e converte para escala de cinza\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Aviso: Imagem '{nome}' não encontrada. Pulando.\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar a imagem '{nome}': {e}. Pulando.\")\n",
    "            continue\n",
    "\n",
    "        # Redimensiona imagem\n",
    "        Ar = Img.resize((20, 20))\n",
    "\n",
    "        An = np.array(Ar) # An = Ar.copy() # An=imnoise(Ar,'gaussian',0,0.005);  # adiciona ruido (requer implementação de ruído)\n",
    "\n",
    "        A = An.astype(np.float64) / 255.0  # converte para double precision (normaliza para 0-1)\n",
    "\n",
    "        a = A.flatten()  # Etapa de vetorizacao: Empilhamento das colunas\n",
    "\n",
    "        ROT = i   # Rotulo = indice do individuo\n",
    "\n",
    "        X.append(a) # Coloca cada imagem vetorizada como linha da matriz X (será transposta depois)\n",
    "        Y.append(ROT) # Coloca o rotulo de cada vetor\n",
    "\n",
    "X = np.array(X).T  # Transpõe para ter cada imagem vetorizada como coluna (como no MATLAB)\n",
    "Y = np.array(Y)\n",
    "\n",
    "print(\"Imagens carregadas e vetorizadas. Dimensão de X:\", X.shape)\n",
    "print(\"Dimensão de Y:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd8077",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 25 # Número de componentes principais\n",
    "pca = PCA(n_components=q)\n",
    "X_reduced = pca.fit_transform(X.T).T # Aplica PCA nas imagens (linhas de X.T) e transpõe de volta\n",
    "\n",
    "# Variância explicada acumulada\n",
    "VEq = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(VEq) + 1), VEq, 'r-', linewidth=3)\n",
    "plt.xlabel('Número de Componentes Principais')\n",
    "plt.ylabel('Variância Explicada Acumulada')\n",
    "plt.title('Variância Explicada Acumulada por PCA')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "X = X_reduced # X agora é o X transformado pelo PCA\n",
    "\n",
    "Z = np.vstack((X, Y))  # Formato 01 vetor de atributos por coluna: DIM(Z) = (p+1)xN\n",
    "Z = Z.T     # Formato 01 vetor de atributos por linha: DIM(Z) = Nx(p+1)\n",
    "\n",
    "print(\"Dados após PCA. Dimensão de X (reduzido):\", X.shape)\n",
    "print(\"Dimensão de Z (final):\", Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('recfaces.dat', Z, fmt='%.6f') # fmt='%.6f' para manter a precisão float\n",
    "\n",
    "print(\"\\nProcessamento de faces concluído. Dados salvos em 'recfaces.dat'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funções placeholder para os classificadores \n",
    "\n",
    "\n",
    "\n",
    "def quadratico(D, Nr, Ptrain):\n",
    "    X_data = D[:, :-1]\n",
    "    y_labels = D[:, -1]\n",
    "\n",
    "    classes = np.unique(y_labels)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    TX_OK = np.zeros(Nr)\n",
    "    \n",
    "    for r in range(Nr):\n",
    "        # 1. Divisão dos dados em treino e teste\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_data, y_labels, test_size=(100 - Ptrain) / 100.0, stratify=y_labels, random_state=r #\n",
    "        )\n",
    "\n",
    "        # Dicionários para armazenar centroides e matrizes de covariância\n",
    "        centroids = {}\n",
    "        cov_matrices = {}\n",
    "        inv_cov_matrices = {}\n",
    "        det_cov_matrices = {}\n",
    "        # 2. Estimar o vetor centroide e a matriz de covariância de cada classe (Passo 1)\n",
    "        for c in classes:\n",
    "            # Selecionar exemplos da classe 'c' no conjunto de treinamento\n",
    "            X_train_c = X_train[y_train == c]\n",
    "            Ni = X_train_c.shape[0]\n",
    "\n",
    "            if Ni == 0:\n",
    "                print(f\"Aviso: Classe {c} não tem exemplos no conjunto de treinamento nesta repetição. Pulando.\")\n",
    "                continue\n",
    "\n",
    "            # m_i: vetor centroide\n",
    "            centroids[c] = np.mean(X_train_c, axis=0)\n",
    "\n",
    "            # C_i: matriz de covariância\n",
    "            # np.cov espera que as linhas sejam as observações e colunas as características.\n",
    "            # Se X_train_c já está nesse formato, np.cov(X_train_c) está correto.\n",
    "            Ci = np.cov(X_train_c, rowvar=False) # rowvar=False -> cada coluna é uma variável, cada linha é uma observação\n",
    "\n",
    "            # Adicionar uma pequena regularização\n",
    "            #epsilon = 1e-6 * np.eye(Ci.shape[0])\n",
    "            #Ci_reg = Ci + epsilon\n",
    "\n",
    "            # Calcular inversa e determinante (para evitar recalcular dentro do loop de teste)\n",
    "            try:\n",
    "                inv_cov_matrices[c] = inv(Ci)\n",
    "                det_cov_matrices[c] = det(Ci)\n",
    "            except np.linalg.LinAlgError:\n",
    "                print(f\"Erro: Matriz de covariância para classe {c} é singular ou mal-condicionada. Adicione mais regularização.\")\n",
    "                # Se ocorrer um erro, pode-se pular esta classe ou atribuir um valor alto para o discriminante.\n",
    "                inv_cov_matrices[c] = None\n",
    "                det_cov_matrices[c] = float('inf')\n",
    "\n",
    "\n",
    "        correct_predictions = 0\n",
    "        # Loop para classificar cada amostra no conjunto de teste\n",
    "        for i, x_test_sample in enumerate(X_test):\n",
    "            true_label = y_test[i]\n",
    "            discriminant_values = {}\n",
    "\n",
    "            for c in classes:\n",
    "                if c not in centroids or inv_cov_matrices.get(c) is None:\n",
    "                    # Se a classe não foi treinada ou houve erro na covariância, atribui um valor alto\n",
    "                    discriminant_values[c] = float('inf')\n",
    "                    continue\n",
    "\n",
    "                m_i = centroids[c]\n",
    "                inv_Ci = inv_cov_matrices[c]\n",
    "                det_Ci = det_cov_matrices[c]\n",
    "\n",
    "                # (x - m_i)\n",
    "                diff = x_test_sample - m_i\n",
    "                # 3. Calcular as distâncias quadráticas (Passo 2)\n",
    "                Qi_x = diff @ inv_Ci @ diff.T\n",
    "\n",
    "    # Deve retornar STATS, TX_OK, X, m, S, posto\n",
    "    print(\"Executando quadratico...\")\n",
    "    # Exemplo de retorno (substitua com a lógica real)\n",
    "    return {'accuracy': np.random.rand() * 100}, np.random.rand(Nr) * 100, None, None, None, None\n",
    "\n",
    "def variante1(D, Nr, Ptrain, param):\n",
    "    # Implemente a lógica da função 'variante1' aqui\n",
    "    # Deve retornar STATS, TX_OK, X, m, S, posto\n",
    "    print(\"Executando variante1...\")\n",
    "    return {'accuracy': np.random.rand() * 100}, np.random.rand(Nr) * 100, None, None, None, None\n",
    "\n",
    "def variante2(D, Nr, Ptrain):\n",
    "    # Implemente a lógica da função 'variante2' aqui\n",
    "    # Deve retornar STATS, TX_OK, X, m, S, posto\n",
    "    print(\"Executando variante2...\")\n",
    "    return {'accuracy': np.random.rand() * 100}, np.random.rand(Nr) * 100, None, None, None, None\n",
    "\n",
    "def variante3(D, Nr, Ptrain, param):\n",
    "    # Implemente a lógica da função 'variante3' aqui\n",
    "    # Deve retornar STATS, TX_OK, X, m, S, posto\n",
    "    print(\"Executando variante3...\")\n",
    "    return {'accuracy': np.random.rand() * 100}, np.random.rand(Nr) * 100, None, None, None, None\n",
    "\n",
    "def variante4(D, Nr, Ptrain):\n",
    "    # Implemente a lógica da função 'variante4' aqui\n",
    "    # Deve retornar STATS, TX_OK, X, m, S, posto\n",
    "    print(\"Executando variante4...\")\n",
    "    return {'accuracy': np.random.rand() * 100}, np.random.rand(Nr) * 100, None, None, None, None\n",
    "\n",
    "def linearMQ(D, Nr, Ptrain):\n",
    "    # Implemente a lógica da função 'linearMQ' aqui\n",
    "    # Deve retornar STATS, TX_OK, W\n",
    "    print(\"Executando linearMQ...\")\n",
    "    return {'accuracy': np.random.rand() * 100}, np.random.rand(Nr) * 100, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados\n",
    "try:\n",
    "    D = np.loadtxt('recfaces.dat')\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: 'recfaces.dat' não encontrado. Por favor, execute 'face_preprocessing_column.py' primeiro.\")\n",
    "    exit()\n",
    "\n",
    "Nr = 50  # No. de repeticoes\n",
    "Ptrain = 80  # Porcentagem de treinamento\n",
    "\n",
    "# Executa os classificadores\n",
    "start_time = time.time()\n",
    "STATS_0, TX_OK0, X0, m0, S0, posto0 = quadratico(D, Nr, Ptrain)\n",
    "Tempo0 = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "STATS_1, TX_OK1, X1, m1, S1, posto1 = variante1(D, Nr, Ptrain, 0.01)\n",
    "Tempo1 = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "STATS_2, TX_OK2, X2, m2, S2, posto2 = variante2(D, Nr, Ptrain)\n",
    "Tempo2 = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "STATS_3, TX_OK3, X3, m3, S3, posto3 = variante3(D, Nr, Ptrain, 0.5)\n",
    "Tempo3 = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "STATS_4, TX_OK4, X4, m4, S4, posto4 = variante4(D, Nr, Ptrain)\n",
    "Tempo4 = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "STATS_5, TX_OK5, W = linearMQ(D, Nr, Ptrain)\n",
    "Tempo5 = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eed8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibe as estatísticas\n",
    "print(\"\\nSTATS_0:\\n\", pd.DataFrame([STATS_0]))\n",
    "print(\"\\nSTATS_1:\\n\", pd.DataFrame([STATS_1]))\n",
    "print(\"\\nSTATS_2:\\n\", pd.DataFrame([STATS_2]))\n",
    "print(\"\\nSTATS_3:\\n\", pd.DataFrame([STATS_3]))\n",
    "print(\"\\nSTATS_4:\\n\", pd.DataFrame([STATS_4]))\n",
    "print(\"\\nSTATS_5:\\n\", pd.DataFrame([STATS_5]))\n",
    "\n",
    "TEMPOS = np.array([Tempo0, Tempo1, Tempo2, Tempo3, Tempo4, Tempo5])\n",
    "print(\"\\nTEMPOS:\", TEMPOS)\n",
    "\n",
    "# Boxplot\n",
    "data_to_plot = [TX_OK0, TX_OK1, TX_OK2, TX_OK3, TX_OK4, TX_OK5]\n",
    "labels = [\"Quadratico\", \"Variante 1\", \"Variante 2\", \"Variante 3\", \"Variante 4\", \"MQ\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(data_to_plot)\n",
    "plt.xticks(range(1, len(labels) + 1), labels, rotation=45, ha='right')\n",
    "plt.title('Conjunto Coluna')\n",
    "plt.xlabel('Classificador')\n",
    "plt.ylabel('Taxas de acerto')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
